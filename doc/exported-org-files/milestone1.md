
# Table of Contents

1.  [Introduction](#org2e315ad)
    1.  [Implementation Language](#orga796869)
    2.  [Tools](#orge976de8)
    3.  [Miscellaneous](#org77bd4b2)
        1.  [Continuous Integration](#org4903363)
        2.  [File Organization](#orgc8748f1)
2.  [Scanner](#orgebcdb11)
    1.  [Semicolon Insertion](#orgfa9ddbd)
    2.  [Block comment support](#orge741fe5)
        1.  [Adding newlines at the end of the file if they aren't present already](#orgf39e453)
    3.  [Nicer error messages](#org647eec2)
3.  [Parser](#org975dc2e)
    1.  [Grammar](#orgebb05cc)
    2.  [AST](#org4a13fc0)
        1.  [Accurate Type Representation](#orge06bc72)
        2.  [Simplified Data Type Categories](#org32c225e)
        3.  [Format Preservation](#orgf24b8a6)
        4.  [Structure Simplification](#org9d50514)
    3.  [Weeding](#orgbcc9487)
4.  [Pretty Printer](#orgd98ae0b)
5.  [Team](#org714e0f5)
    1.  [Team Organization](#org670be79)
    2.  [Contributions](#org6e0cfe2)

This document is for explaining the design decisions we had to make
whilst implementing the components for milestone 1.


<a id="org2e315ad"></a>

# Introduction


<a id="orga796869"></a>

## Implementation Language

For our `GoLite` compiler, we decided to use `Haskell` as the
implementation language, as many of the required tasks can be done
more naturally (i.e. tree traversal, recursing over self defined
structures, enforcing types, etc.).


<a id="orge976de8"></a>

## Tools

For scanning, we use the program `Alex`, which is very similar to `flex`
but produces `Haskell` code instead. Additionally, we use `Happy` for
parsing which resembles `bison/yacc`. `Alex` and `Happy` can be interlinked
quite nicely together, passing on useful information (encompassed
through a state monad), like line number, column number, offset in
file and error messages (which can be propagated in a pure manner
without having to raise exceptions).

There are several other good scanning/parsing options to use with
Haskell, such as `Megaparsec`, however, we stuck with `Alex/Happy` because
they are most similar to `flex/bison` that we learned in class and most
of us were familiar with the syntax.

We use `stack` to manage our Haskell project, including `GHC`, the
respective projects and tests, additional tests which we implemented
using the `hspec` package.


<a id="org77bd4b2"></a>

## Miscellaneous


<a id="org4903363"></a>

### Continuous Integration

We used Travis CI to build our project on every push, as well as
run our tests to make sure that pushes kept things working.


<a id="orgc8748f1"></a>

### File Organization

-   `src/`
    -   `generated/`
        -   Files generated by `golite.y` using `Happy` and `golite.x` using `Alex`
    -   Modules for each feature
-   `app/`
    -   `Main.hs` (main, imports the needed modules and uses
        `ParseCLI` to parse the command line arguments and call the
        function we want)
-   `test/`
    -   `Spec.hs` (auto discovers `hspec` tests to run them all with
        `stack test`)
    -   Spec modules, each exposing a test suite


<a id="orgebcdb11"></a>

# Scanner

The first step of this milestone was to scan user input into
tokens. Most of the tokens we had to account for were straightforward
and similar to the assignments, however we had to encompass a few of
the quirks/more complicated things relating to `GoLite` compared to
something simple like `MiniLang`.


<a id="orgfa9ddbd"></a>

## Semicolon Insertion

The first hurdle of scanning was semicolon insertion. To solve
this, we use start codes in `Alex` and have special rules for
certain states, i.e. if the last token we scanned was something
that can take an optional semicolon, we'd enter the \(nl\) state and
encountering a newline in said state would scan the newline to a
semicolon, otherwise scanning anything else (that isn't
whitespace/ignored), would return to the default state (\(0\)), where
newlines are just ignored. This seems to be a nice/elegant solution
as we don't have to traverse the whole list or get any context of
any sort, other than the start code which is a feature built in to
`Alex`. It also makes a lot more sense to let the scanner handle
such situations and to replace newlines by semicolons in certain
scenarios (rather than arbitrarily inserting semicolons when given
some situations).


<a id="orge741fe5"></a>

## Block comment support

Block comments cannot be easily scanned using only regular
expressions. One potential solution was to use start codes again
(changing state upon opening a comment), although that would
potentially add a lot more states because we'd have to combine
possibilities with the newline insertion state (because block
comments that span over newlines should also insert semicolons when
they're optional). Another thing is that using a state approach
made it harder to catch the error of an unclosed comment block.

In our solution we iterate through the scanner's input once we
receive an open comment block and ignore everything until we close
the block comment and if we never reach a close then we can easily
emit an error.

In addition, we had to account for semicolon insertion with block
comments, which we were able to do by setting a semicolon flag to
true if we encounter any new line in the characters inside the
block comment and then we insert a semicolon if the start code is
\(nl\), which was conveniently available for us.


<a id="orgf39e453"></a>

### Adding newlines at the end of the file if they aren't present already

`Go` adds a semicolon at the end of a file even if there's no
newline at the end of the file for semicolon insertion. In order
to enforce this, we simply make sure every program scanned ends
with a newline, by appending a newline if it doesn't already end
with a newline (preprocess string input before scanning). This was
the easiest solution as otherwise we'd have to try and insert a
semicolon if we were in the \(nl\) state when we encounter an `EOF`
(but we have to return an `EOF` and couldn't return a semicolon
and an `EOF`).


<a id="org647eec2"></a>

## Nicer error messages

We decided to use `ErrorBundle` from `Megaparsec` in order to
output nicer error messages. While we did have access to offset,
line and column when generating error messages, we did not have
access to the entire source file string (the scanner would not keep
it at each step). So, in order to generate the contextual part of
the source file showing where the error is, we modified the `monad`
wrapper provided with `Alex` (see `TokensBase.hs`) and changed the
`Alex` monad to wrap over a `Either (String, Int) a` instead of
`Either String a`, i.e. instead of just an error message on the
left side we also carry an `Int` which represents the offset of the
error so that when we want to print the error message at the end we
can append the part in the source file where the error occurred.


<a id="org975dc2e"></a>

# Parser


<a id="orgebb05cc"></a>

## Grammar

Certain productions match a list and an item of that list,
resulting in a new list. Because our lists our immutable, we
decided to prepend the items to our list and reverse them in
another production that uses said list, as appending each time
would have been a lot more costly in terms of speed.

With regards to the parsing rules, we initially wanted to avoid 
reversing ourselves with each usage. However, we noticed that adding 
an extra non terminal to manage reversals for each list made our 
generated module notably more compelx, so we decided against it.


<a id="org4a13fc0"></a>

## AST

The AST is largely a one to one mapping of the Golang specs, with
parts we don't support removed and additional parts for Golite added.

In some cases, there are minor deviations from the CFG.


<a id="orge06bc72"></a>

### Accurate Type Representation

We model our ast as accurately as possible, such that impossible
states are forbidden. We lack any checks for compatible types at
this stage, but we can match the definition for 'exactly one', 'one
or more', and 'zero or one'. In cases like identifiers, a [list](https://golang.org/ref/spec#IdentifierList) is
one or more (haskell `NonEmpty`), yet many locations make it
optional. While a direct translation would be `Maybe (NonEmpty a)`,
we choose to make it `[a]` as it makes more sense.


<a id="org32c225e"></a>

### Simplified Data Type Categories

Some splits, such as `add_op` and `mul_op` are distinguished
purely to demonstrate precedence; they are in fact only used once
in the specs, so we decide to merge them directly in our `ArithmOp`
model. Several other instances exist.

Given we created an AST vs a CST, we can further compact parts of
the grammar. For instance, an if clause in the spec leads to an
`IfStmt` grammar, whose `else` body is either a block (with
surrounding braces) or another if statement (no surrounding
braces). However, in our case, we don't need to model the braces,
so we can treat the else body exclusively as `Stmt` vs `Either
    Block IfStmt`.


<a id="orgf24b8a6"></a>

### Format Preservation

By design, our types for `int` and `string` specify whether they
are hex/octal/dec or raw/interpreted respectively. We kept this
information so that our pretty print would accurately represent
the input, even though we can convert them all to a single type
(eg dec and interpreted).


<a id="org9d50514"></a>

### Structure Simplification

For var and type declaration, we make no distinction between
single declaration (exactly one) and block declaration (0 or
more). Unlike types, which produce different formats, we decide to
enforce all declarations of one var to be single declaration. In
other words, `var ( a = 2 )` would become `var a = 2`. Note that
we cannot further simplify group declarations `var ( a, b = 2,
    3)`, as there is no guarantee at this stage that the number of
identifiers matches the number of values. This would have to be
checked at a later stage


<a id="orgbcc9487"></a>

## Weeding

In our first stage, our weeding operations are simple, and don't rely 
on context outside of the statement we are verifying. As a result, 
we were able to define recursive traversal methods to verify relevant 
statements, and create verifiers that validate at a single level.
Haskell helped immensely here, as we were able to use pattern matching 
to produce performant and independent functions.
Each verifier returns an optional error, and we are able to map the results 
and return the first error, if any.


<a id="orgd98ae0b"></a>

# Pretty Printer


<a id="org714e0f5"></a>

# Team


<a id="org670be79"></a>

## Team Organization

TODO


<a id="org6e0cfe2"></a>

## Contributions

-   **Julian Lore** Wrote the majority of the scanner and handled weird

cases, wrote a large amount of valid/invalid programs, implemented
many other tests (`hspec` or small tests in our program) and looked
over the parser, contributing a few things to it as well.

-   **David Lougheed:** Wrote the bulk of the parser grammar and contributed to

the weeder. Also wrote 3 of the valid programs and 8 of the
invalid ones and had minor contributions to miscellaneous other components.

-   **Allan Wang** Created the AST and helper classes for pretty printing

and error handling.  Wrote the base package for testing as well as
some of the embedded test cases within `hspec`.  Added integrations
(Travis + Slack), and gave code reviews to the other components.

