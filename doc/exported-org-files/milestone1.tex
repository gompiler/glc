% Created 2019-03-02 Sat 17:04
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\usepackage[margin=1in]{geometry}
\author{Lore, J., Lougheed D., Wang A.}
\date{\today}
\title{Design Document for Milestone 1}
\hypersetup{
 pdfauthor={Lore, J., Lougheed D., Wang A.},
 pdftitle={Design Document for Milestone 1},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 26.1 (Org mode 9.2.1)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents

This document is for explaining the design decisions we had to make
whilst implementing the components for milestone 1.
\section{Introduction}
\label{sec:org4d3385e}
\subsection{Implementation Language}
\label{sec:org4c5c0c6}
For our \texttt{GoLite} compiler, we decided to use \texttt{Haskell} as the
implementation language, as many of the required tasks can be done
more naturally (i.e. tree traversal, recursing over self defined
structures, enforcing types, etc.).
\subsection{Tools}
\label{sec:org4c89b6b}
For scanning, we use the program \texttt{Alex}, which is very similar to \texttt{flex}
but produces \texttt{Haskell} code instead. Additionally, we use \texttt{Happy} for
parsing, which resembles \texttt{bison/yacc}. \texttt{Alex} and \texttt{Happy} can be interlinked
quite nicely, passing on useful information (encompassed
through a state monad) like the line number, column number, character
offset in file, and error messages (which can be propagated in a pure manner
without having to raise exceptions).

There are several other good scanning/parsing options to use with
Haskell, such as \texttt{Megaparsec}, however, we stuck with \texttt{Alex/Happy} because
they are most similar to \texttt{flex/bison} that we learned in class and most
of us were familiar with the syntax.

We use \texttt{stack} to manage our Haskell project, including \texttt{GHC}, the
respective projects and tests, additional tests which we implemented
using the \texttt{hspec} package.
\subsection{Miscellaneous}
\label{sec:org32b68d8}
\subsubsection{Continuous Integration}
\label{sec:org2448d5d}
We use Travis CI to build our project on every push, as well as
run our tests to make sure that new changes did not break any
existing functionality.
\subsubsection{File Organization}
\label{sec:org1ddc6fd}
\begin{itemize}
\item \texttt{src/}
\begin{itemize}
\item \texttt{generated/}
\begin{itemize}
\item Code generated by \texttt{golite.y}, using \texttt{Happy}, and \texttt{golite.x}, using \texttt{Alex}
\end{itemize}
\item Modules for each feature
\end{itemize}
\item \texttt{app/}
\begin{itemize}
\item \texttt{Main.hs} (main, imports the needed modules and uses
\texttt{ParseCLI} to parse the command line arguments and call the
function we want)
\end{itemize}
\item \texttt{test/}
\begin{itemize}
\item \texttt{Spec.hs} (auto discovers \texttt{hspec} tests to run them all with
\texttt{stack test})
\item Spec modules, each exposing a test suite
\end{itemize}
\end{itemize}
\section{Scanner}
\label{sec:orgdb98011}
The first step of this milestone was to scan user input into
tokens. Most of the tokens we had to account for were straightforward
and similar to the assignments. However, we had to encompass a few of
the quirks/more complicated things relating to \texttt{GoLite} compared to
something simple like \texttt{MiniLang}.
\subsection{Semicolon Insertion}
\label{sec:orgf48ff83}
The first hurdle of scanning was semicolon insertion. To solve
this, we use start codes in \texttt{Alex} and have special rules for
certain states.

If the last token we scanned was something
that can take an optional semicolon, we enter the \(nl\) state, where
encountering a newline would transform the newline into a
semicolon. Scanning anything else (that isn't whitespace or otherwise
ignored) returns the scanner to the default state (\(0\)), where
newlines are just ignored.

This seems to be an elegant solution, as we don't have to traverse
the whole list or store context other than the start code, a
built-in feature of \texttt{Alex}. It also makes a lot more sense to let
the scanner handle these situations automatically rather than trying
to handle them using the parser.
\subsection{Block comment support}
\label{sec:orge7c44bf}
Block comments cannot be easily scanned using only regular
expressions. One potential solution was to use start codes again
(changing state upon opening a comment), although that would
potentially add a lot more states because we'd have to combine
possibilities with the newline insertion state: (as block
comments that span over newlines should also insert semicolons when
they're optional). Another thing is that using a state approach
made it harder to catch the error of an unclosed comment block.

In our implemented solution, we iterate through the scanner's input
once we receive an open comment block and ignore everything until we
close the block comment. If the comment never closes, we can easily
emit an error.

To account for semicolon insertion with block comments, we set a
semicolon flag to true if we encounter any new line inside the
block comment, and we insert a semicolon if the start code is
\(nl\), the aforementioned newline insertion state.
\subsubsection{Adding newlines at the end of the file if they aren't present already}
\label{sec:orgf002d2d}
\texttt{Go} requires a semicolon or newline at the end of function
declarations. Sometimes, there may not be a newline at the end of
a file, so no semicolon insertion occurs.

In order to correct for this type of file, we enforce a final
newline by appending one if necessary. To do this, the code string
is preprocessed prior to scanning. This was the easiest solution
as otherwise we'd have to try and insert a semicolon if we were in
the \(nl\) state when we encounter an \texttt{EOF}, while also making sure
to return an \texttt{EOF}. This would be difficult without additional
context information.
\subsection{Nicer error messages}
\label{sec:orgce3b2bd}
We decided to use \texttt{ErrorBundle} from \texttt{Megaparsec} in order to
output nicer error messages, with program context for easier
debugging from an end-user programming perspective:

\begin{verbatim}
Error: parsing error, unexpected ) at 5:22:                                                                
  |
5 | func abstract(a, b, c) {
  |                      ^
\end{verbatim}

While we did have access to character offset, line, and column when
generating error messages, we did not have access to the entire
source file string, as the default behaviour of the scanner is to not
keep the entire string at each step.

In order to generate the contextual message, we modified the \texttt{monad}
wrapper provided with \texttt{Alex} (see \texttt{TokensBase.hs}) and changed the
\texttt{Alex} monad to wrap over a \texttt{Either (String, Int) a} instead of
\texttt{Either String a}, i.e. in addition to storing an error message on
the left side of the monad we also carry an \texttt{Int} which represents
the offset of the error, so that when we want to print the error
message at the end we can append the part in the source file where
the error occurred.
\section{Parser}
\label{sec:org5860e5a}
\subsection{Grammar}
\label{sec:org448cef8}
Many of our difficulties in the grammar were associated with identifier and
expression lists. Two constructs in the Go (and GoLite) spec are identifier
lists, used in declarations and function signatures, and expression lists,
used in assignment and function signatures. The grammar was refactored to
avoid this problem by allowing identifier lists to become expression lists
if needed in a way which avoided introducing other conflicts.

Another difficulty we had was with list ordering. LR parsers
work more intuitively with rules that put the newly-created terminal
after the recursively-expanding non-terminal However, since Haskell
uses recursive lists defined in the opposite way, it is significantly
faster to prepend items rather than append them. Although more
performant, this prepending results in a reversed ordering, which
must be handled after the list is 'complete'.

We initially wanted to avoid reversing the lists ourselves with each usage.
However, adding an extra non terminal to manage reversals for each list made
our generated module notably more complex and needlessly increased our
grammar size, so we decided against it.
\subsection{AST}
\label{sec:org5c57c24}
The AST is largely a one to one mapping of the Golang specs, with
parts we don't support removed and additional parts for Golite added.

In some cases, there are minor deviations from the CFG.
\subsubsection{Accurate Type Representation}
\label{sec:org7b18d26}
We model our ast as accurately as possible, such that impossible
states are forbidden. We lack any checks for compatible types at
this stage, but we can match the definition for 'exactly one', 'one
or more', and 'zero or one'. In cases like identifiers, a \href{https://golang.org/ref/spec\#IdentifierList}{list} is
one or more (haskell \texttt{NonEmpty}), yet many locations make it
optional. While a direct translation would be \texttt{Maybe (NonEmpty a)},
we choose to make it \texttt{[a]} as it makes more sense.
\subsubsection{Simplified Data Type Categories}
\label{sec:org4d6118c}
Some splits, such as \texttt{add\_op} and \texttt{mul\_op} are distinguished
purely to demonstrate precedence; they are in fact only used once
in the specs, so we decide to merge them directly in our \texttt{ArithmOp}
model. Several other instances exist.

Given we created an AST vs a CST, we can further compact parts of
the grammar. For instance, an if clause in the spec leads to an
\texttt{IfStmt} grammar, whose \texttt{else} body is either a block (with
surrounding braces) or another if statement (no surrounding
braces). However, in our case, we don't need to model the braces,
so we can treat the else body exclusively as \texttt{Stmt} vs \texttt{Either
    Block IfStmt}.
\subsubsection{Format Preservation}
\label{sec:org9e01a1b}
By design, our types for \texttt{int} and \texttt{string} specify whether they
are hex/octal/dec or raw/interpreted respectively. We kept this
information so that our pretty print would accurately represent
the input, even though we can convert them all to a single type
(eg dec and interpreted).
\subsubsection{Structure Simplification}
\label{sec:org7e5e843}
For \texttt{var} and \texttt{type} declaration, we make no distinction between
single declaration (exactly one) and block declaration (0 or
more). Unlike types, which produce different formats, we decide to
enforce all declarations of one var to be single declaration. In
other words, \texttt{var ( a = 2 )} would become \texttt{var a = 2}. Note that
we cannot further simplify group declarations \texttt{var ( a, b = 2,
    3)}, as there is no guarantee at this stage that the number of
identifiers matches the number of values. This would have to be
checked at a later stage
\subsection{Weeding}
\label{sec:org11727ac}
In our first stage, our weeding operations are simple, and don't rely
on context outside of the statement we are verifying. As a result,
we were able to define recursive traversal methods to verify relevant
statements, and create verifiers that validate at a single level.
Haskell helped immensely here, as we were able to use pattern matching
to produce performant and independent functions.
Each verifier returns an optional error, and we are able to map the results
and return the first error, if any.
\section{Pretty Printer}
\label{sec:org76db7d5}
TODO
\section{Team}
\label{sec:org75fd43f}
\subsection{Team Organization}
\label{sec:orgc5604c4}
TODO
\subsection{Contributions}
\label{sec:org32e390e}
\begin{itemize}
\item \textbf{Julian Lore:} Wrote the majority of the scanner and handled weird
cases, wrote a large amount of valid/invalid programs, implemented
many other tests (\texttt{hspec} or small tests in our program) and looked
over the parser, contributing a few things to it as well.
\item \textbf{David Lougheed:} Wrote the bulk of the parser grammar and contributed to
the weeder. Also wrote 3 of the valid programs and 8 of the
invalid ones and had minor contributions to miscellaneous other components.
Contributed to the testing of the parser and pretty printer.
\item \textbf{Allan Wang:} Created the AST and helper classes for pretty printing
and error handling.  Wrote the base package for testing as well as
some of the embedded test cases within \texttt{hspec}.  Added integrations
(Travis + Slack), and gave code reviews to the other components.
\end{itemize}
\end{document}