#+TITLE: Design Document for Milestone 1
#+AUTHOR: Lore, J., Lougheed D., Wang A.
#+LATEX_HEADER: \usepackage[margin=1in]{geometry}
This document is for explaining the design decisions we had to make
whilst implementing the components for milestone 1.
* Introduction
** Implementation Language
   For our ~GoLite~ compiler, we decided to use ~Haskell~ as the
   implementation language, as many of the required tasks can be done
   more naturally (i.e. tree traversal, recursing over self defined
   structures, enforcing types, etc.).
** Tools
   For scanning, we use the program ~Alex~, which is very similar to ~flex~
   but produces ~Haskell~ code instead. Additionally, we use ~Happy~ for
   parsing, which resembles ~bison/yacc~. ~Alex~ and ~Happy~ can be interlinked
   quite nicely, passing on useful information (encompassed
   through a state monad) like the line number, column number, character
   offset in file, and error messages (which can be propagated in a pure manner
   without having to raise exceptions).

   There are several other good scanning/parsing options to use with
   Haskell, such as ~Megaparsec~, however, we stuck with ~Alex/Happy~ because
   they are most similar to ~flex/bison~ that we learned in class and most
   of us were familiar with the syntax.

   We use ~stack~ to manage our Haskell project, including ~GHC~, the
   respective projects and tests, additional tests which we implemented
   using the ~hspec~ package.
** Miscellaneous
*** Continuous Integration
    We use Travis CI to build our project on every push, as well as
    run our tests to make sure that new changes did not break any
    existing functionality.
*** File Organization
    - ~src/~
      - ~generated/~
        - Code generated by ~golite.y~, using ~Happy~, and ~golite.x~, using ~Alex~
      - Modules for each feature
    - ~app/~
      - ~Main.hs~ (main, imports the needed modules and uses
        ~ParseCLI~ to parse the command line arguments and call the
        function we want)
    - ~test/~
      - ~Spec.hs~ (auto discovers ~hspec~ tests to run them all with
        ~stack test~)
      - Spec modules, each exposing a test suite
* Scanner
  The first step of this milestone was to scan user input into
  tokens. Most of the tokens we had to account for were straightforward
  and similar to the assignments. However, we had to encompass a few of
  the quirks/more complicated things relating to ~GoLite~ compared to
  something simple like ~MiniLang~.
** Semicolon Insertion
   The first hurdle of scanning was semicolon insertion. To solve
   this, we use start codes in ~Alex~ and have special rules for
   certain states.

   If the last token we scanned was something
   that can take an optional semicolon, we enter the $nl$ state, where
   encountering a newline would transform the newline into a
   semicolon. Scanning anything else (that isn't whitespace or otherwise
   ignored) returns the scanner to the default state ($0$), where
   newlines are just ignored.

   This seems to be an elegant solution, as we don't have to traverse
   the whole list or store context other than the start code, a
   built-in feature of ~Alex~. It also makes a lot more sense to let
   the scanner handle these situations automatically rather than trying
   to handle them using the parser.
** Block comment support
   Block comments cannot be easily scanned using only regular
   expressions. One potential solution was to use start codes again
   (changing state upon opening a comment), although that would
   potentially add a lot more states because we'd have to combine
   possibilities with the newline insertion state: (as block
   comments that span over newlines should also insert semicolons when
   they're optional). Another thing is that using a state approach
   made it harder to catch the error of an unclosed comment block.

   In our implemented solution, we iterate through the scanner's input
   once we receive an open comment block and ignore everything until we
   close the block comment. If the comment never closes, we can easily
   emit an error.

   To account for semicolon insertion with block comments, we set a
   semicolon flag to true if we encounter any new line inside the
   block comment, and we insert a semicolon if the start code is
   $nl$, the aforementioned newline insertion state.
*** Adding newlines at the end of the file if they aren't present already
    ~Go~ adds a semicolon at the end of a file even if there's no
    newline at the end of the file for semicolon insertion. In order
    to enforce this, we simply make sure every program scanned ends
    with a newline, by appending a newline if it doesn't already end
    with a newline (preprocess string input before scanning). This was
    the easiest solution as otherwise we'd have to try and insert a
    semicolon if we were in the $nl$ state when we encounter an ~EOF~
    (but we have to return an ~EOF~ and couldn't return a semicolon
    and an ~EOF~).
** Nicer error messages
   We decided to use ~ErrorBundle~ from ~Megaparsec~ in order to
   output nicer error messages. While we did have access to character offset,
   line, and column when generating error messages, we did not have
   access to the entire source file string (the scanner would not keep
   it at each step). In order to generate a contextual message showing
   where the error is in the source file, we modified the ~monad~
   wrapper provided with ~Alex~ (see ~TokensBase.hs~) and changed the
   ~Alex~ monad to wrap over a ~Either (String, Int) a~ instead of
   ~Either String a~, i.e. instead of just an error message on the
   left side we also carry an ~Int~ which represents the offset of the
   error so that when we want to print the error message at the end we
   can append the part in the source file where the error occurred.
* Parser
** Grammar
   Many of our difficulties in the grammar were associated with identifier and
   expression lists. Two constructs in the Go (and GoLite) spec are identifier
   lists, used in declarations and function signatures, and expression lists,
   used in assignment and function signatures. The grammar was refactored to
   avoid this problem by allowing identifier lists to become expression lists
   if needed in a way which avoided introducing other conflicts.

   Another difficulty we had was with list ordering. LR parsers
   work more intuitively with rules that put the newly-created terminal
   after the recursively-expanding non-terminal However, since Haskell
   uses recursive lists defined in the opposite way, it is significantly
   faster to prepend items rather than append them. Although more
   performant, this prepending results in a reversed ordering, which
   must be handled after the list is 'complete'.

   We initially wanted to avoid reversing the lists ourselves with each usage.
   However, adding an extra non terminal to manage reversals for each list made
   our generated module notably more complex and needlessly increased our
   grammar size, so we decided against it.
** AST
   The AST is largely a one to one mapping of the Golang specs, with
   parts we don't support removed and additional parts for Golite added.

   In some cases, there are minor deviations from the CFG.
*** Accurate Type Representation
    We model our ast as accurately as possible, such that impossible
    states are forbidden. We lack any checks for compatible types at
    this stage, but we can match the definition for 'exactly one', 'one
    or more', and 'zero or one'. In cases like identifiers, a [[https://golang.org/ref/spec#IdentifierList][list]] is
    one or more (haskell ~NonEmpty~), yet many locations make it
    optional. While a direct translation would be ~Maybe (NonEmpty a)~,
    we choose to make it ~[a]~ as it makes more sense.
*** Simplified Data Type Categories
    Some splits, such as ~add_op~ and ~mul_op~ are distinguished
    purely to demonstrate precedence; they are in fact only used once
    in the specs, so we decide to merge them directly in our ~ArithmOp~
    model. Several other instances exist.

    Given we created an AST vs a CST, we can further compact parts of
    the grammar. For instance, an if clause in the spec leads to an
    ~IfStmt~ grammar, whose ~else~ body is either a block (with
    surrounding braces) or another if statement (no surrounding
    braces). However, in our case, we don't need to model the braces,
    so we can treat the else body exclusively as ~Stmt~ vs ~Either
    Block IfStmt~.
*** Format Preservation
    By design, our types for ~int~ and ~string~ specify whether they
    are hex/octal/dec or raw/interpreted respectively. We kept this
    information so that our pretty print would accurately represent
    the input, even though we can convert them all to a single type
    (eg dec and interpreted).
*** Structure Simplification
    For ~var~ and ~type~ declaration, we make no distinction between
    single declaration (exactly one) and block declaration (0 or
    more). Unlike types, which produce different formats, we decide to
    enforce all declarations of one var to be single declaration. In
    other words, ~var ( a = 2 )~ would become ~var a = 2~. Note that
    we cannot further simplify group declarations ~var ( a, b = 2,
    3)~, as there is no guarantee at this stage that the number of
    identifiers matches the number of values. This would have to be
    checked at a later stage
** Weeding
    In our first stage, our weeding operations are simple, and don't rely
    on context outside of the statement we are verifying. As a result,
    we were able to define recursive traversal methods to verify relevant
    statements, and create verifiers that validate at a single level.
    Haskell helped immensely here, as we were able to use pattern matching
    to produce performant and independent functions.
    Each verifier returns an optional error, and we are able to map the results
    and return the first error, if any.
* Pretty Printer
* Team
** Team Organization
   TODO
** Contributions
- *Julian Lore:* Wrote the majority of the scanner and handled weird
   cases, wrote a large amount of valid/invalid programs, implemented
   many other tests (~hspec~ or small tests in our program) and looked
   over the parser, contributing a few things to it as well.
- *David Lougheed:* Wrote the bulk of the parser grammar and contributed to
   the weeder. Also wrote 3 of the valid programs and 8 of the
   invalid ones and had minor contributions to miscellaneous other components.
   Contributed to the testing of the parser and pretty printer.
- *Allan Wang:* Created the AST and helper classes for pretty printing
   and error handling.  Wrote the base package for testing as well as
   some of the embedded test cases within ~hspec~.  Added integrations
   (Travis + Slack), and gave code reviews to the other components.
